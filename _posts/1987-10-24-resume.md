---
layout: post
title: "RESUME"
categories: resume
---

### 1 基本情况
---
**姓名：刘炜**

**性别：男**

**出生年月：1987年10月**

**Tel: 159 0164 2637**

**E-mail: stupidlw [at] 126.com**

### 2 教育经历
---

*2006年9月 ~ 2010年6月 [华中科技大学](http://www.hust.edu.cn) [计算机学院](http://cs.hust.edu.cn/) 信息安全 工学学士*

*2010年8月 ~ 2013年2月 华中科技大学 计算机学院 计算机系统结构 [集群与网格计算实验室](http://grid.hust.edu.cn/) 计算机系统结构 工学硕士*

### 3 工作经历
---

**2013年3月 ~ 2014年4月 北京搜狐集团 精准广告研发中心 广告研发工程师**

* _广告投放服务器研发与重构 (Ad Server)_
  * 用pipeline的模式，与UA(User Attribute),PA(Page Attribute),AdIndex,CTR(Click Through Rate),AdExchange等模块进行数据交互,完成广告投放
  * Keywords：nginx, fastcgi, redis, thrift, epoll, 多线程

* _搜狐广告RTB系统研发（Ad Exchange）_
  * 将广告竞价请求发送给多家dsp竞价，要求dsp在100ms内完成竞价
  * Keywords：动态连接池，tcp协议栈调优，管理竞价事件，处理竞价超时，流量控制，连接错误自动检测，protobuf

* _广告服务本地缓存透明代理（Local Cache）_
  * 广告投放机需要和远程的UA,PA,AdIndex,CTR模块基于thrift进行数据交互，LocalCache充分利用投放机本地多余的内存，在投放机和RPC服务之间充当透明代理的角色，加速数据查询
  * 在本项目中为了最大限度地减少响应时间，针对thrift协议进行了详细分析，直接缓存RPC序列化后的二进制数据，去掉了不必要的反序列化操作
  * 本项目使用C语言开发，预分配好大块内存，对预分配的内存进行管理
  * 使用二项堆实现了超时机制

**2014年4月 ~ 2015年11月 上海倾听信息技术有限公司(蜻蜓FM) 高级后台开发工程师**

* _基于zmq开发的轻量级消息中间件，用于推荐系统的后台数据交互_
  * 基于zmq的pub-sub, req-rep, push-pop模式实现消息中间件平台
  * 客户端可以动态创建、销毁以上三种模式的zmq消息队列
  * zmq不支持消息持久化，该中间件在服务端实现了消息持久化，为了提升持久化过程的读写性能，采用mmap完成IO操作，实现了零拷贝（zero copy）

* _根据用户推荐数据实现的自动化推送系统_
  * 每天将离线处理好的用户推荐数据读入，选取为用户推荐的第一条内容，在该用户最活跃的时段（通过历史收听数据得出用户的活跃时段）向用户推送内容
  * 采用leveldb按时间段分库存储待推送信息，在每个时段对对应库中的用户完成推送
  * 对用户分组进行AB测试，评测推荐算法效果

* _广告平台_
  * 广告管理系统：对开源软件[revive-adserver](http://www.revive-adserver.com/)进行修改，满足蜻蜓FM的广告管理要求
  * 广告投放机：采用C语言实现的高效异步api服务，实现广告投放，在单核1G的Ubuntu服务器上，单台qps达到一万
  * 广告检索服务：每分钟从mysql异步加载广告，在内存中建立二级倒排拉链（dnf算法），对广告进行索引，用于提供对定向广告的实时检索服务
  * 广告日志处理：每半小时对所有广告投放服务器上的日志进行汇总处理，计算每个广告的投放数据，写入数据库，用于数据报表的制作和CPM合约广告到量自动停止投放

* _日志系统升级与重构_
  * 采用ngx_kafka_module，完成日志从nginx直接发送到kafka集群，后端的kafka消费端实时进行消费，并每小时把日志上传到阿里云的[OSS](http://www.aliyun.com/product/oss/)服务
  * 采用flume把一部分日志写入到HDFS，供spark进行流式处理（内容推荐部分）和供Hadoop进行离线数据处理（使用Hive进行数据统计）
  * 搭建zookeeper，kafka，flume

* _API缓存框架重构_
  * 蜻蜓FM的用户api有两级缓存，CDN和SLB，以前在SLB层使用的是nginx自带的proxy_cache，而proxy_cache的不足在于更新缓慢和大量小文件占用过多inode（会使服务器inode耗尽导致无法创建新的磁盘文件），另外由于proxy_cache的purge操作是异步的，导致无法保证CDN和SLB的purge次序
  * 采用redis-cluster替代proxy_cache进行重构，使用基于ngx_lua实现的redis-cluster-resty模块实现api缓存，并利用该操作的同步特性，来保证SLB和CDN缓存purge的有序性。另外为了实现对目录的purge操作，对redis-cluster进行了小的修改，为redis增加了一个根据正则表达式批量删除key的命令（根据redis使用的three clause BSD license许可，修改后的代码需要被开源，该分支的地址在[https://github.com/brg-liuwei/redis](https://github.com/brg-liuwei/redis)）
  * 在CMS更新内容后，需要对api缓存进行purge，我们的api数据库采用的主从架构，内容更新是在master上，需要等到所有slave都同步完成后才能进行CDN回源，为此实现了一个小工具管理purge请求，每条purge请求对应的内容在所有slave都同步完成之后才发送到SLB和CDN

**2015年11月 ~ 2016年6月 上海珍岛集团 架构师**

* 负责臻优DSP项目的架构设计与后台开发，两个月上线了第一版产品，完成了同优酷、好耶和百度ADX的对接，日消耗峰值近二十万人民币，单机(8核16G)qps超过3万，超时率（100ms）低于5%
* 离职原因：不认可直属领导灌鸡汤打鸡血越俎代庖强制要求我下属加班的外包管理文化和脱离商务拍脑袋做产品的混账思维方式 （PS:若贵司也是这样的文化，请千万__不要__通知我来面试）


### 4 Side Project
---

#### [ngx_kafka_module](https://github.com/brg-liuwei/ngx_kafka_module)

该项目是开发一个[nginx](http://nginx.org/)模块，用于将post数据直接转发到对应的[kafka](http://kafka.apache.org/) topic之中，可以用于日志消费等场景。在传统的使用kafka收集日志的场景中，需要web服务器先将客户端上报的日志临时存储在本地磁盘，再使用[tail2kafka](https://github.com/harelba/tail2kafka)等工具，将磁盘上的日志上传到kafka集群。而使用该模块的好处是可以不需要临时的磁盘空间，日志可以直接通过nginx高效异步地发送到kafka集群，简化了使用kafka收集日志的操作，也提高日志收集服务的性能。

#### [json4c](https://github.com/brg-liuwei/json4c)

这是在业余时间用C语言实现的一个轻量级json库，对比标准的[cJSON](http://cjson.sourceforge.net/)库，json4c使用了内存池管理每个json对象，防止频繁的内存分配，并简化了内存管理。另外，json4c也支持Unicode编码。该库在生产环境中也被多次使用。

#### [cctools](https://github.com/brg-liuwei/cctools)

一些常用的C++工具库，包括配置文件读取、日志、时间、内存池和网络等。其中网络部分的设计采用了react模式，并在编译期做了平台检测，可以使用Linux平台的epoll和OSX的kqueue这两种高效的IO多路复用工具。

#### [gotools](https://github.com/brg-liuwei/gotools)

一些常用的golang工具库，其中一些比较有趣的功能有日志rotate以及自动超时删除map。

#### [lua-resty-redis-session](https://github.com/brg-liuwei/lua-resty-redis-session)

用[ngx_lua](https://www.nginx.com/resources/wiki/modules/lua/)开发web server需要用到会话管理功能，目前[openresty](http://openresty.org/)还没有官方的会话管理工具，目前已有的基于ngx_lua的会话管理工具有[lua-resty-session](https://github.com/bungle/lua-resty-session)，这是基于SecuritySession协议（该协议把用户信息通过加密的方式存放在cookie中实现会话管理）实现的一个会话管理工具。而lua-resty-redis-session则是用了另一种会话管理手段，即把用户信息存放在服务端。该工具使用redis作为存储层，使用openresty包提供的[lua-resty-redis](https://github.com/openresty/lua-resty-redis)读写redis中存储的会话信息，可以方便地针对redis-cluster进行扩展。

#### [godnf](https://github.com/brg-liuwei/godnf)

使用go语言实现的广告检索算法dnf (Disjunctive Normal Form) 库，该算法参考论文 [Indexing Boolean Expressions](http://theory.stanford.edu/~sergei/papers/vldb09-indexing.pdf)。可以使用godnf包实现快速的布尔表达式检索。

### 5 自我评价
---

* 熟练使用C，C++，golang，lua进行项目开发
* 熟练使用基本的算法和数据结构，在unix环境下能够熟练进行软件开发和运维
* 喜欢钻研技术，曾研读过nginx，redis，leveldb，memcache等著名开源项目的源代码，并从阅读分析高质量源码中学习技术
* 关注openresty社区，关注nginx社区的发展
* 希望能够深入学习并实践互联网广告技术
